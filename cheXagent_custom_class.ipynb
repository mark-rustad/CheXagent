{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "\n",
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, dataframe, prompts, processor_pretrained_model=\"StanfordAIMI/CheXagent-8b\"):\n",
    "        self.dataframe = dataframe\n",
    "        self.prompts = prompts\n",
    "        self.processor = AutoProcessor.from_pretrained(processor_pretrained_model, trust_remote_code=True)\n",
    "\n",
    "        # Create a list of tuples, each containing an image path and a prompt\n",
    "        self.image_prompt_pairs = [\n",
    "            (row[\"image_path\"], prompt) for _, row in self.dataframe.iterrows() for _, prompt in self.prompts.items()\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_prompt_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, prompt = self.image_prompt_pairs[index]\n",
    "        full_image_path = f\"{image_path}\"\n",
    "        image = Image.open(full_image_path).convert(\"RGB\")\n",
    "\n",
    "        inputs = self.processor(images=[image], text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}  # Adjust as necessary\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "column_names = [\"image_index\", \"finding_labels\", \"follow_up_number\", \"patient_id\", \"patient_age\", \"patient_gender\", \"view_position\", \"original_image_width\", \"original_image_height\", \"original_image_pixel_spacing_x\", \"original_image_pixel_spacing_y\"]  # fmt: skip # nopep8\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"./data/NIH_Chest_X-ray_Dataset/Data_Entry_2017.csv\",\n",
    "    names=column_names,\n",
    "    header=0,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "# import prompts dictionary\n",
    "with open(\"output/prompts.json\", \"r\") as json_file:\n",
    "    prompts = json.load(json_file)\n",
    "\n",
    "\n",
    "results_prev = pd.read_csv(\n",
    "    \"output/disease_classification_QA.csv\",\n",
    "    usecols=[\"image_index\", \"finding_labels\", \"prompt_key\", \"response\"],\n",
    "    dtype=str,\n",
    ")\n",
    "\n",
    "\n",
    "# images with missing prompt cases\n",
    "images_incomplete = (\n",
    "    results_prev.groupby([\"image_index\"], as_index=True, sort=False)[\"prompt_key\"]\n",
    "    .apply(lambda x: x.nunique())\n",
    "    .pipe(lambda x: x[x != len(prompts)])\n",
    "    .index.to_list()\n",
    ")\n",
    "\n",
    "# images that have been analyed\n",
    "images_analyzed = set(results_prev[\"image_index\"].values) - set(images_incomplete)\n",
    "\n",
    "# images to input into CheXagent\n",
    "images_not_analyzed = set(data[\"image_index\"].values) - images_analyzed\n",
    "subset = data[data[\"image_index\"].isin(images_not_analyzed) & (\n",
    "    (data[\"finding_labels\"].str.count(\"\\\\|\") + 1) == 1)].sample(5).copy()\n",
    "\n",
    "subset[\"image_path\"] = [next(Path(\"data/NIH_Chest_X-ray_Dataset\").rglob(x)).as_posix()\n",
    "                        for x in subset[\"image_index\"].values]\n",
    "\n",
    "display(subset.head())\n",
    "print(f\"nRows: {subset.shape[0]:,}\\tnColumns: {subset.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# Assuming `dataframe`, `image_folder_path`, and `prompts` are already defined\n",
    "dataset = CheXpertDataset(subset, prompts)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)  # Batch size set to 1 for simplicity\n",
    "processor = dataset.processor\n",
    "\n",
    "# Load the model and set it to evaluation mode\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "\n",
    "model_name = \"StanfordAIMI/CheXagent-8b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=dtype, trust_remote_code=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load generation config if needed\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "\n",
    "# Perform text generation\n",
    "for batch in data_loader:\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "    # Generate text; adjust depending on your model's API\n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "\n",
    "    # Decode and print the generated text\n",
    "    generated_text = [processor.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "total_seg_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
